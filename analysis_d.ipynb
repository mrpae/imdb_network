{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Network Analysis\n",
    "\n",
    "This notebook supports the analysis part of our project. We assume that you already have a DuckDB instance filled with necessary tables. If not, please visit `setup.ipynb`.\n",
    "\n",
    "Let's start with basic imports and connecting to our database."
   ],
   "id": "eb471ce730c0673f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:59:35.770955Z",
     "start_time": "2025-05-29T20:59:35.752484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!pip install -r requirements.txt\n",
    "#!pip install duckdb"
   ],
   "id": "d0296f7733477917",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:59:43.666340Z",
     "start_time": "2025-05-29T20:59:40.349571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to a persistent DuckDB database file\n",
    "conn = duckdb.connect(\"imdb.duckdb\")"
   ],
   "id": "d616e11ac5bc4e2d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As mentioned in the setup, we are dealing with 7 tables:\n",
    "1. `name_basics`\n",
    "2. `title_akas`\n",
    "3. `title_basics`\n",
    "4. `title_crew`\n",
    "5. `title_episode`\n",
    "6. `title_principals`\n",
    "7. `title_ratings`\n",
    "\n",
    "The following query shows a detailed overview about our schema."
   ],
   "id": "fc026bba41dc3d1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T20:59:43.836598Z",
     "start_time": "2025-05-29T20:59:43.734174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = conn.execute(\"\"\"\n",
    "SELECT table_name, column_name, data_type\n",
    "FROM information_schema.columns\n",
    "WHERE table_schema = 'main'\n",
    "ORDER BY table_name, ordinal_position;\n",
    "\"\"\").df()\n",
    "\n",
    "display(df)"
   ],
   "id": "98428403b9c36e61",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          table_name                column_name  data_type\n",
       "0        name_basics                     nconst    VARCHAR\n",
       "1        name_basics               primary_name    VARCHAR\n",
       "2        name_basics                 birth_year    INTEGER\n",
       "3        name_basics                 death_year    INTEGER\n",
       "4        name_basics         primary_profession  VARCHAR[]\n",
       "5        name_basics           known_for_titles  VARCHAR[]\n",
       "6         title_akas                   title_id    VARCHAR\n",
       "7         title_akas  CAST(ordering AS INTEGER)    INTEGER\n",
       "8         title_akas                      title    VARCHAR\n",
       "9         title_akas                     region    VARCHAR\n",
       "10        title_akas                   language    VARCHAR\n",
       "11        title_akas                      types  VARCHAR[]\n",
       "12        title_akas                 attributes  VARCHAR[]\n",
       "13        title_akas          is_original_title    BOOLEAN\n",
       "14      title_basics                     tconst    VARCHAR\n",
       "15      title_basics                 title_type    VARCHAR\n",
       "16      title_basics              primary_title    VARCHAR\n",
       "17      title_basics             original_title    VARCHAR\n",
       "18      title_basics                   is_adult    BOOLEAN\n",
       "19      title_basics                 start_year    INTEGER\n",
       "20      title_basics                   end_year    INTEGER\n",
       "21      title_basics            runtime_minutes    INTEGER\n",
       "22      title_basics                     genres  VARCHAR[]\n",
       "23        title_crew                     tconst    VARCHAR\n",
       "24        title_crew                  directors  VARCHAR[]\n",
       "25        title_crew                    writers  VARCHAR[]\n",
       "26     title_episode                     tconst    VARCHAR\n",
       "27     title_episode              parent_tconst    VARCHAR\n",
       "28     title_episode              season_number    INTEGER\n",
       "29     title_episode             episode_number    INTEGER\n",
       "30  title_principals                     tconst    VARCHAR\n",
       "31  title_principals  CAST(ordering AS INTEGER)    INTEGER\n",
       "32  title_principals                     nconst    VARCHAR\n",
       "33  title_principals                   category    VARCHAR\n",
       "34  title_principals                        job    VARCHAR\n",
       "35  title_principals                 characters    VARCHAR\n",
       "36     title_ratings                     tconst    VARCHAR\n",
       "37     title_ratings             average_rating      FLOAT\n",
       "38     title_ratings                  num_votes    INTEGER"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table_name</th>\n",
       "      <th>column_name</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name_basics</td>\n",
       "      <td>nconst</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>name_basics</td>\n",
       "      <td>primary_name</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name_basics</td>\n",
       "      <td>birth_year</td>\n",
       "      <td>INTEGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>name_basics</td>\n",
       "      <td>death_year</td>\n",
       "      <td>INTEGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>name_basics</td>\n",
       "      <td>primary_profession</td>\n",
       "      <td>VARCHAR[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>name_basics</td>\n",
       "      <td>known_for_titles</td>\n",
       "      <td>VARCHAR[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>title_akas</td>\n",
       "      <td>title_id</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>title_akas</td>\n",
       "      <td>CAST(ordering AS INTEGER)</td>\n",
       "      <td>INTEGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>title_akas</td>\n",
       "      <td>title</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>title_akas</td>\n",
       "      <td>region</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>title_akas</td>\n",
       "      <td>language</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>title_akas</td>\n",
       "      <td>types</td>\n",
       "      <td>VARCHAR[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>title_akas</td>\n",
       "      <td>attributes</td>\n",
       "      <td>VARCHAR[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>title_akas</td>\n",
       "      <td>is_original_title</td>\n",
       "      <td>BOOLEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>title_basics</td>\n",
       "      <td>tconst</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>title_basics</td>\n",
       "      <td>title_type</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>title_basics</td>\n",
       "      <td>primary_title</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>title_basics</td>\n",
       "      <td>original_title</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>title_basics</td>\n",
       "      <td>is_adult</td>\n",
       "      <td>BOOLEAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>title_basics</td>\n",
       "      <td>start_year</td>\n",
       "      <td>INTEGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>title_basics</td>\n",
       "      <td>end_year</td>\n",
       "      <td>INTEGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>title_basics</td>\n",
       "      <td>runtime_minutes</td>\n",
       "      <td>INTEGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>title_basics</td>\n",
       "      <td>genres</td>\n",
       "      <td>VARCHAR[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>title_crew</td>\n",
       "      <td>tconst</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>title_crew</td>\n",
       "      <td>directors</td>\n",
       "      <td>VARCHAR[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>title_crew</td>\n",
       "      <td>writers</td>\n",
       "      <td>VARCHAR[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>title_episode</td>\n",
       "      <td>tconst</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>title_episode</td>\n",
       "      <td>parent_tconst</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>title_episode</td>\n",
       "      <td>season_number</td>\n",
       "      <td>INTEGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>title_episode</td>\n",
       "      <td>episode_number</td>\n",
       "      <td>INTEGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>title_principals</td>\n",
       "      <td>tconst</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>title_principals</td>\n",
       "      <td>CAST(ordering AS INTEGER)</td>\n",
       "      <td>INTEGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>title_principals</td>\n",
       "      <td>nconst</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>title_principals</td>\n",
       "      <td>category</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>title_principals</td>\n",
       "      <td>job</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>title_principals</td>\n",
       "      <td>characters</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>title_ratings</td>\n",
       "      <td>tconst</td>\n",
       "      <td>VARCHAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>title_ratings</td>\n",
       "      <td>average_rating</td>\n",
       "      <td>FLOAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>title_ratings</td>\n",
       "      <td>num_votes</td>\n",
       "      <td>INTEGER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The following cell lists all titles and actors along with other interesting information (average rating, runtime, country, etc.). This should be useful for analysis.",
   "id": "4145a962372f2f34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:00:41.327468Z",
     "start_time": "2025-05-29T20:59:43.946573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        tb.tconst,\n",
    "        tb.primary_title AS movie_title,\n",
    "        tb.start_year,\n",
    "        tb.runtime_minutes,\n",
    "        tb.genres,\n",
    "        tr.average_rating,\n",
    "        tr.num_votes,\n",
    "        nb.primary_name AS actor_name,\n",
    "        nb.birth_year,\n",
    "        nb.primary_profession,\n",
    "        tp.category,\n",
    "        tp.characters,\n",
    "        ta.region\n",
    "    FROM title_basics tb\n",
    "    JOIN title_ratings tr \n",
    "        ON tb.tconst = tr.tconst\n",
    "    JOIN title_principals tp\n",
    "        ON tb.tconst = tp.tconst\n",
    "    JOIN name_basics nb\n",
    "        ON tp.nconst = nb.nconst\n",
    "    JOIN title_akas ta\n",
    "        ON tb.tconst = ta.title_id\n",
    "    WHERE tb.title_type = 'movie'\n",
    "        AND tb.start_year >= 2010\n",
    "        AND tb.start_year <= 2024\n",
    "        AND ta.region = 'US'\n",
    "        AND tp.category IN ('actor', 'actress')\n",
    "        AND tb.genres IS NOT NULL AND array_length(genres) > 0\n",
    "        AND tb.runtime_minutes IS NOT NULL AND tb.runtime_minutes > 15\n",
    "    ORDER BY tr.average_rating DESC, tr.num_votes DESC\n",
    "\"\"\").df()\n",
    "\n",
    "display(df.head(10))"
   ],
   "id": "94bd8b9cfd80e7e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48cafc925ccc440a99fc5032b0bc7425"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "       tconst             movie_title  start_year  runtime_minutes   genres  \\\n",
       "0  tt15461714  King B.'s Hate... Love        2021               85  [Drama]   \n",
       "1  tt15461714  King B.'s Hate... Love        2021               85  [Drama]   \n",
       "2  tt15461714  King B.'s Hate... Love        2021               85  [Drama]   \n",
       "3  tt15461714  King B.'s Hate... Love        2021               85  [Drama]   \n",
       "4  tt15461714  King B.'s Hate... Love        2021               85  [Drama]   \n",
       "5  tt15461714  King B.'s Hate... Love        2021               85  [Drama]   \n",
       "6  tt15461714  King B.'s Hate... Love        2021               85  [Drama]   \n",
       "7  tt15461714  King B.'s Hate... Love        2021               85  [Drama]   \n",
       "8  tt15461714  King B.'s Hate... Love        2021               85  [Drama]   \n",
       "9  tt15461714  King B.'s Hate... Love        2021               85  [Drama]   \n",
       "\n",
       "   average_rating  num_votes                actor_name  birth_year  \\\n",
       "0            10.0         14         Cookie Pearl Reid        <NA>   \n",
       "1            10.0         14  Brian 'Da Wildcat' Smith        <NA>   \n",
       "2            10.0         14                   King B.        <NA>   \n",
       "3            10.0         14             Brandall Cole        <NA>   \n",
       "4            10.0         14                 Damn Fool        <NA>   \n",
       "5            10.0         14            Brandon Glover        <NA>   \n",
       "6            10.0         14                    Oz Man        <NA>   \n",
       "7            10.0         14              Maria Geiger        <NA>   \n",
       "8            10.0         14      Tiphanie Nichole Rae        <NA>   \n",
       "9            10.0         14               Olivia Gant        <NA>   \n",
       "\n",
       "            primary_profession category    characters region  \n",
       "0     [actress, miscellaneous]  actress     [\"Susan\"]     US  \n",
       "1    [actor, writer, producer]    actor    [\"Grimmy\"]     US  \n",
       "2  [actor, director, producer]    actor  [\"Royal T.\"]     US  \n",
       "3    [actor, writer, director]    actor    [\"Robber\"]     US  \n",
       "4              [actor, writer]    actor        [\"Ed\"]     US  \n",
       "5                      [actor]    actor     [\"Chump\"]     US  \n",
       "6                      [actor]    actor       [\"Ant\"]     US  \n",
       "7                    [actress]  actress     [\"Donna\"]     US  \n",
       "8                    [actress]  actress   [\"Rachael\"]     US  \n",
       "9                    [actress]  actress       [\"Eve\"]     US  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>movie_title</th>\n",
       "      <th>start_year</th>\n",
       "      <th>runtime_minutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>actor_name</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>primary_profession</th>\n",
       "      <th>category</th>\n",
       "      <th>characters</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt15461714</td>\n",
       "      <td>King B.'s Hate... Love</td>\n",
       "      <td>2021</td>\n",
       "      <td>85</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Cookie Pearl Reid</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[actress, miscellaneous]</td>\n",
       "      <td>actress</td>\n",
       "      <td>[\"Susan\"]</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt15461714</td>\n",
       "      <td>King B.'s Hate... Love</td>\n",
       "      <td>2021</td>\n",
       "      <td>85</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Brian 'Da Wildcat' Smith</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[actor, writer, producer]</td>\n",
       "      <td>actor</td>\n",
       "      <td>[\"Grimmy\"]</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt15461714</td>\n",
       "      <td>King B.'s Hate... Love</td>\n",
       "      <td>2021</td>\n",
       "      <td>85</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>King B.</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[actor, director, producer]</td>\n",
       "      <td>actor</td>\n",
       "      <td>[\"Royal T.\"]</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt15461714</td>\n",
       "      <td>King B.'s Hate... Love</td>\n",
       "      <td>2021</td>\n",
       "      <td>85</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Brandall Cole</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[actor, writer, director]</td>\n",
       "      <td>actor</td>\n",
       "      <td>[\"Robber\"]</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt15461714</td>\n",
       "      <td>King B.'s Hate... Love</td>\n",
       "      <td>2021</td>\n",
       "      <td>85</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Damn Fool</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[actor, writer]</td>\n",
       "      <td>actor</td>\n",
       "      <td>[\"Ed\"]</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt15461714</td>\n",
       "      <td>King B.'s Hate... Love</td>\n",
       "      <td>2021</td>\n",
       "      <td>85</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Brandon Glover</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[actor]</td>\n",
       "      <td>actor</td>\n",
       "      <td>[\"Chump\"]</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tt15461714</td>\n",
       "      <td>King B.'s Hate... Love</td>\n",
       "      <td>2021</td>\n",
       "      <td>85</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Oz Man</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[actor]</td>\n",
       "      <td>actor</td>\n",
       "      <td>[\"Ant\"]</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tt15461714</td>\n",
       "      <td>King B.'s Hate... Love</td>\n",
       "      <td>2021</td>\n",
       "      <td>85</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Maria Geiger</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[actress]</td>\n",
       "      <td>actress</td>\n",
       "      <td>[\"Donna\"]</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tt15461714</td>\n",
       "      <td>King B.'s Hate... Love</td>\n",
       "      <td>2021</td>\n",
       "      <td>85</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Tiphanie Nichole Rae</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[actress]</td>\n",
       "      <td>actress</td>\n",
       "      <td>[\"Rachael\"]</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tt15461714</td>\n",
       "      <td>King B.'s Hate... Love</td>\n",
       "      <td>2021</td>\n",
       "      <td>85</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>Olivia Gant</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>[actress]</td>\n",
       "      <td>actress</td>\n",
       "      <td>[\"Eve\"]</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:00:41.463800Z",
     "start_time": "2025-05-29T21:00:41.448778Z"
    }
   },
   "cell_type": "code",
   "source": "len(df)",
   "id": "aa5dd2f2ce3935b4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "733067"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:00:43.670112Z",
     "start_time": "2025-05-29T21:00:42.079257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.drop_duplicates(subset=['tconst', 'actor_name', 'category'], inplace=True)\n",
    "len(df)"
   ],
   "id": "f45d8fc893ef7320",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "613700"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Collaboration graph",
   "id": "4e3cf5b6baa0f146"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:00:47.606919Z",
     "start_time": "2025-05-29T21:00:43.745072Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install networkx",
   "id": "b082c83362e6decf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in c:\\users\\wyh5232\\vscprojects\\imdb_network\\.venv\\lib\\site-packages (3.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:01:13.198694Z",
     "start_time": "2025-05-29T21:00:47.770065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "G_collabs = nx.Graph()\n",
    "\n",
    "for tconst, group in df.groupby('tconst'):\n",
    "    actors = group['actor_name'].tolist()\n",
    "    for actor1, actor2 in combinations(actors, 2):\n",
    "        if actor1 == actor2:\n",
    "            continue\n",
    "        # Add nodes excplicitly to add name attributes\n",
    "        if not G_collabs.has_node(actor1):\n",
    "            G_collabs.add_node(actor1, name=actor1)\n",
    "        if not G_collabs.has_node(actor2):\n",
    "            G_collabs.add_node(actor2, name=actor2)\n",
    "        # Add edge with weight\n",
    "        if G_collabs.has_edge(actor1, actor2):\n",
    "            G_collabs[actor1][actor2]['weight'] += 1\n",
    "        else:\n",
    "            G_collabs.add_edge(actor1, actor2, weight=1)\n"
   ],
   "id": "388a14b79cf352e6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:01:14.259424Z",
     "start_time": "2025-05-29T21:01:13.498877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Group by actor_name and count the number of movies\n",
    "actor_movie_counts = df.groupby('actor_name').size().reset_index(name='movie_count')\n",
    "\n",
    "# Sort by movie count in descending order\n",
    "sorted_actors = actor_movie_counts.sort_values('movie_count', ascending=False)\n",
    "\n",
    "# Get the actor with the most movies\n",
    "most_movies_actor = sorted_actors.iloc[0]\n",
    "actor_name_most = most_movies_actor['actor_name']\n",
    "num_movies_most = most_movies_actor['movie_count']\n",
    "\n",
    "# Get the actor with the second most movies\n",
    "second_most_movies_actor = sorted_actors.iloc[1]\n",
    "actor_name_second = second_most_movies_actor['actor_name']\n",
    "num_movies_second = second_most_movies_actor['movie_count']\n",
    "\n",
    "print(f\"Actor with the most movies: {actor_name_most} (Number of movies: {num_movies_most})\")\n",
    "print(f\"Actor with the second most movies: {actor_name_second} (Number of movies: {num_movies_second})\")"
   ],
   "id": "cc5739377cec782d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor with the most movies: Eric Roberts (Number of movies: 272)\n",
      "Actor with the second most movies: Danny Trejo (Number of movies: 106)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:01:19.229098Z",
     "start_time": "2025-05-29T21:01:14.622344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Calculate total collaborations per actor (sum of edge weights)\n",
    "collaboration_counts = {\n",
    "    node: sum(data['weight'] for _, _, data in G_collabs.edges(node, data=True))\n",
    "    for node in G_collabs.nodes\n",
    "}\n",
    "\n",
    "sorted_actors = sorted(collaboration_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "most_connected_actor, total_collaborations = sorted_actors[0]\n",
    "second_connected_actor, second_total_collaborations = sorted_actors[1]\n",
    "\n",
    "# Find how many unique actors they collaborated with (degree)\n",
    "first_unique_collaborators = len(list(G_collabs.neighbors(most_connected_actor)))\n",
    "second_unique_collaborators = len(list(G_collabs.neighbors(second_connected_actor)))\n",
    "\n",
    "print(f\"Most connected actor: {most_connected_actor}\")\n",
    "print(f\"Total collaborations: {total_collaborations}\")\n",
    "print(f\"Unique actors collaborated with: {first_unique_collaborators}\")\n",
    "\n",
    "print(f\"Second most connected actor: {second_connected_actor}\")\n",
    "print(f\"Total collaborations: {second_total_collaborations}\")\n",
    "print(f\"Unique actors collaborated with: {second_unique_collaborators}\")\n"
   ],
   "id": "a082068dfcae9114",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most connected actor: Eric Roberts\n",
      "Total collaborations: 2394\n",
      "Unique actors collaborated with: 2131\n",
      "Second most connected actor: Danny Trejo\n",
      "Total collaborations: 943\n",
      "Unique actors collaborated with: 835\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:01:20.489374Z",
     "start_time": "2025-05-29T21:01:20.041504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sort actors by the number of collabs (degree) in descending order\n",
    "sorted_actors = sorted(G_collabs.degree, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Actor with the most collabs\n",
    "most_collabs_actor = sorted_actors[0]\n",
    "# Get the actor with the second most collabs\n",
    "second_most_collabs_actor = sorted_actors[1]\n",
    "\n",
    "# Extract the actor's name and number of collabs\n",
    "actor_name_most_collabs = G_collabs.nodes[most_collabs_actor[0]]['name']\n",
    "num_collabs_most = most_collabs_actor[1]\n",
    "\n",
    "# Extract the actor's name and number of collabs\n",
    "actor_name_2most_collabs = G_collabs.nodes[second_most_collabs_actor[0]]['name']\n",
    "num_collabs_second = second_most_collabs_actor[1]\n",
    "\n",
    "print(f\"Actor with the most collabs: {actor_name_most_collabs} (Number of collabs: {num_collabs_most})\")\n",
    "print(f\"Actor with the second most collabs: {actor_name_2most_collabs} (Number of collabs: {num_collabs_second})\")"
   ],
   "id": "b0965cf60cef1fc7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor with the most collabs: Eric Roberts (Number of collabs: 2131)\n",
      "Actor with the second most collabs: Danny Trejo (Number of collabs: 835)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### PageRank as a measure of influence\n",
    "why: An actor who collaborates with many well-connected actors gets a higher score, \n",
    "meaning that the number of connections is not as important as being connected to well-connected actors.\n",
    "It handles weighted graphs well.\n",
    "\n",
    "pagerank - who has reach\n",
    "eigenvector- who's elite"
   ],
   "id": "772a136cb100c2a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:02:24.163723Z",
     "start_time": "2025-05-29T21:01:50.390638Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install scipy",
   "id": "d616740f28c25167",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-29T21:01:21.797098Z",
     "start_time": "2025-05-29T21:01:21.146045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pagerank = nx.pagerank(G_collabs, weight='weight')\n",
    "nx.set_node_attributes(G_collabs, pagerank, name='pagerank')\n",
    "\n",
    "eigen_centrality = nx.eigenvector_centrality(G_collabs, max_iter=1000, weight='weight')\n",
    "nx.set_node_attributes(G_collabs, eigen_centrality, name='eigen_centrality')"
   ],
   "id": "237b38b271cc3c33",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m pagerank \u001B[38;5;241m=\u001B[39m \u001B[43mnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpagerank\u001B[49m\u001B[43m(\u001B[49m\u001B[43mG_collabs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m nx\u001B[38;5;241m.\u001B[39mset_node_attributes(G_collabs, pagerank, name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpagerank\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m eigen_centrality \u001B[38;5;241m=\u001B[39m nx\u001B[38;5;241m.\u001B[39meigenvector_centrality(G_collabs, max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m, weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\VscProjects\\imdb_network\\.venv\\lib\\site-packages\\networkx\\utils\\decorators.py:788\u001B[0m, in \u001B[0;36margmap.__call__.<locals>.func\u001B[1;34m(_argmap__wrapper, *args, **kwargs)\u001B[0m\n\u001B[0;32m    787\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfunc\u001B[39m(\u001B[38;5;241m*\u001B[39margs, __wrapper\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 788\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m argmap\u001B[38;5;241m.\u001B[39m_lazy_compile(__wrapper)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m<class 'networkx.utils.decorators.argmap'> compilation 4:3\u001B[0m, in \u001B[0;36margmap_pagerank_1\u001B[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling, backend, **backend_kwargs)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mbz2\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mcollections\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mgzip\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01minspect\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mitertools\u001B[39;00m\n",
      "File \u001B[1;32m~\\VscProjects\\imdb_network\\.venv\\lib\\site-packages\\networkx\\utils\\backends.py:967\u001B[0m, in \u001B[0;36m_dispatchable.__call__\u001B[1;34m(self, backend, *args, **kwargs)\u001B[0m\n\u001B[0;32m    965\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m backend \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnetworkx\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    966\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbackend\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m backend is not installed\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 967\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39morig_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    969\u001B[0m \u001B[38;5;66;03m# Use `backend_name` in this function instead of `backend`.\u001B[39;00m\n\u001B[0;32m    970\u001B[0m \u001B[38;5;66;03m# This is purely for aesthetics and to make it easier to search for this\u001B[39;00m\n\u001B[0;32m    971\u001B[0m \u001B[38;5;66;03m# variable since \"backend\" is used in many comments and log/error messages.\u001B[39;00m\n\u001B[0;32m    972\u001B[0m backend_name \u001B[38;5;241m=\u001B[39m backend\n",
      "File \u001B[1;32m~\\VscProjects\\imdb_network\\.venv\\lib\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:111\u001B[0m, in \u001B[0;36mpagerank\u001B[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;129m@nx\u001B[39m\u001B[38;5;241m.\u001B[39m_dispatchable(edge_attrs\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mweight\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mpagerank\u001B[39m(\n\u001B[0;32m     12\u001B[0m     G,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     19\u001B[0m     dangling\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     20\u001B[0m ):\n\u001B[0;32m     21\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Returns the PageRank of the nodes in the graph.\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \n\u001B[0;32m     23\u001B[0m \u001B[38;5;124;03m    PageRank computes a ranking of the nodes in the graph G based on\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    109\u001B[0m \n\u001B[0;32m    110\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 111\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_pagerank_scipy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    112\u001B[0m \u001B[43m        \u001B[49m\u001B[43mG\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpersonalization\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnstart\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdangling\u001B[49m\n\u001B[0;32m    113\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\VscProjects\\imdb_network\\.venv\\lib\\site-packages\\networkx\\algorithms\\link_analysis\\pagerank_alg.py:454\u001B[0m, in \u001B[0;36m_pagerank_scipy\u001B[1;34m(G, alpha, personalization, max_iter, tol, nstart, weight, dangling)\u001B[0m\n\u001B[0;32m    369\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Returns the PageRank of the nodes in the graph.\u001B[39;00m\n\u001B[0;32m    370\u001B[0m \n\u001B[0;32m    371\u001B[0m \u001B[38;5;124;03mPageRank computes a ranking of the nodes in the graph G based on\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    451\u001B[0m \u001B[38;5;124;03m   http://dbpubs.stanford.edu:8090/pub/showDoc.Fulltext?lang=en&doc=1999-66&format=pdf\u001B[39;00m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m--> 454\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msp\u001B[39;00m\n\u001B[0;32m    456\u001B[0m N \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(G)\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m N \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'scipy'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install sklearn",
   "id": "dcd0fd876d55d323"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "centrality_df = pd.DataFrame.from_dict(pagerank, orient='index', columns=['pagerank'])\n",
    "centrality_df['eigenvector'] = pd.Series(eigen_centrality)\n",
    "# Scale pagerank to range [0, 0.5]\n",
    "pagerank_scaler = MinMaxScaler(feature_range=(0, 0.5))\n",
    "centrality_df['pagerank_scaled'] = pagerank_scaler.fit_transform(centrality_df[['pagerank']])\n",
    "# Scale eigenvector centrality to range [0, 0.5]\n",
    "eigenvector_scaler = MinMaxScaler(feature_range=(0, 0.5))\n",
    "centrality_df['eigenvector_scaled'] = eigenvector_scaler.fit_transform(centrality_df[['eigenvector']])\n",
    "# Combine scaled pagerank and eigenvector centrality\n",
    "centrality_df['page_plus_eigen_scaled'] = centrality_df['pagerank_scaled'] + centrality_df['eigenvector_scaled']\n",
    "\n",
    "degree_dict = dict(G_collabs.degree())  # Unweighted degree — just the number of neighbors\n",
    "centrality_df['degree'] = pd.Series(degree_dict)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# KMEANS clustering on pagerank\n",
    "X = scaler.fit_transform(centrality_df[['pagerank']])\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "centrality_df['tier_page'] = kmeans.fit_predict(X)\n",
    "\n",
    "# KMEANS clustering on eigenvector centrality\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(centrality_df[['eigenvector']])\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "centrality_df['tier_eigen'] = kmeans.fit_predict(X)\n",
    "\n",
    "#KMEANS clustering on pagerank + eigenvector centrality\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(centrality_df[['page_plus_eigen_scaled']])\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "centrality_df['tier_combined'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Map sorted cluster index to labels to have meaningful names\n",
    "labels = ['A-list', 'B-list', 'C-list', 'D-list']\n",
    "tier_means = centrality_df.groupby('tier_page')['pagerank'].mean().sort_values(ascending=False)\n",
    "tier_to_label = {tier: label for tier, label in zip(tier_means.index, labels)}\n",
    "\n",
    "centrality_df['tier_label_pr'] = centrality_df['tier_page'].map(tier_to_label)\n",
    "\n",
    "labels = ['A-list', 'B-list', 'C-list', 'D-list']\n",
    "tier_means = centrality_df.groupby('tier_eigen')['eigenvector'].mean().sort_values(ascending=False)\n",
    "tier_to_label = {tier: label for tier, label in zip(tier_means.index, labels)}\n",
    "\n",
    "centrality_df['tier_label_ev'] = centrality_df['tier_eigen'].map(tier_to_label)\n",
    "\n",
    "labels = ['A-list', 'B-list', 'C-list', 'D-list']\n",
    "tier_means = centrality_df.groupby('tier_combined')['page_plus_eigen_scaled'].mean().sort_values(ascending=False)\n",
    "tier_to_label = {tier: label for tier, label in zip(tier_means.index, labels)}\n",
    "\n",
    "centrality_df['tier_label_comb'] = centrality_df['tier_combined'].map(tier_to_label)\n",
    "centrality_df['name'] = centrality_df.index.map(lambda node: G_collabs.nodes[node]['name'])\n",
    "\n",
    "# Add tier labels to nodes in the graph\n",
    "for node, data in centrality_df.iterrows():\n",
    "    if node in G_collabs.nodes:\n",
    "        G_collabs.nodes[node]['tier_label_pr'] = data['tier_label_pr']  # Pagerank-based tier\n",
    "        G_collabs.nodes[node]['tier_label_ev'] = data['tier_label_ev']  # Eigenvector-based tier\n",
    "        G_collabs.nodes[node]['tier_label_comb'] = data['tier_label_comb']  # Combined tier"
   ],
   "id": "7a9b76426fbf2e71"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "G_collabs.nodes.get('Eric Roberts')",
   "id": "6f8334ffac44cd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install seaborn",
   "id": "ef5104095bb94709"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize a dictionary to store connections between tiers\n",
    "tier_connections = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "# Iterate through all edges in the graph\n",
    "for node1, node2 in G_collabs.edges():\n",
    "    # Get the tiers of the two connected nodes\n",
    "    tier1 = centrality_df.loc[node1, 'tier_label_comb'] if node1 in centrality_df.index else 'Unknown'\n",
    "    tier2 = centrality_df.loc[node2, 'tier_label_comb'] if node2 in centrality_df.index else 'Unknown'\n",
    "    \n",
    "    # Increment the connection count for the tier pair\n",
    "    tier_connections[tier1][tier2] += 1\n",
    "    if tier1 != tier2:\n",
    "        tier_connections[tier2][tier1] += 1  # Count the reverse connection as well\n",
    "\n",
    "# Calculate tier sizes\n",
    "tier_sizes = centrality_df['tier_label_comb'].value_counts().to_dict()\n",
    "tier_percentages = defaultdict(lambda: defaultdict(float))\n",
    "\n",
    "# Calculate percentages and display results\n",
    "for tier1 in sorted(tier_connections.keys()):\n",
    "    total_connections = sum(tier_connections[tier1].values())\n",
    "    print(f\"Tier {tier1} connections:\")\n",
    "    for tier2, count in tier_connections[tier1].items():\n",
    "        percentage_of_tier1 = (count / total_connections) * 100 if total_connections > 0 else 0\n",
    "        tier_percentages[tier1][tier2] = percentage_of_tier1\n",
    "        print(f\"  To Tier {tier2}: {count} connections ({percentage_of_tier1:.2f}%)\")\n",
    "    print()\n",
    "\n",
    "# Convert to a DataFrame for visualization\n",
    "tier_percentages_df = pd.DataFrame(tier_percentages).fillna(0)\n",
    "tier_order = ['A-list', 'B-list', 'C-list', 'D-list']\n",
    "tier_percentages_df = tier_percentages_df.reindex(index=tier_order, columns=tier_order, fill_value=0)#.T\n",
    "print(tier_percentages_df)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(tier_percentages_df, annot=True, fmt=\".2f\", cmap=\"Blues\", cbar_kws={'label': 'Percentage of Connections (%)'})\n",
    "plt.title(\"Percentage of Connections Between Tiers\")\n",
    "plt.xlabel(\"Source Tier\")\n",
    "plt.ylabel(\"Target Tier\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "d4de7598ea250be2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "for tier in sorted(centrality_df['tier_label_pr'].unique()):\n",
    "    sub = centrality_df[centrality_df['tier_label_pr'] == tier]\n",
    "    print(f\"Tier based on PageRank {tier}:\")\n",
    "    print(\"  Avg PageRank:\", round(sub['pagerank'].mean(), 7))\n",
    "    print(\"  Avg Eigenvector:\", round(sub['eigenvector'].mean(), 7))\n",
    "    print(\"  Avg Page + Eigen:\", round(sub['page_plus_eigen_scaled'].mean(), 4))\n",
    "    print(\"  Avg Nr of Degrees:\", round(sub['degree'].mean(), 2))\n",
    "    print(\"  Median Nr of Degrees:\", round(sub['degree'].median(), 2))\n",
    "    print(\"  Nr of actors/actresses:\", len(sub))\n",
    "    print(\"  Sample actors:\", [a for a in sub['name'].head(5)])\n",
    "\n",
    "print('-------------------------------------')\n",
    "for tier in sorted(centrality_df['tier_label_ev'].unique()):\n",
    "    sub = centrality_df[centrality_df['tier_label_ev'] == tier]\n",
    "    print(f\"Tier based on Eigenvector {tier}:\")\n",
    "    print(\"  Avg PageRank:\", round(sub['pagerank'].mean(), 7))\n",
    "    print(\"  Avg Eigenvector:\", round(sub['eigenvector'].mean(), 7))\n",
    "    print(\"  Avg Page + Eigen:\", round(sub['page_plus_eigen_scaled'].mean(), 4))\n",
    "    print(\"  Avg Nr of Degrees:\", round(sub['degree'].mean(), 2))\n",
    "    print(\"  Median Nr of Degrees:\", round(sub['degree'].median(), 2))\n",
    "    print(\"  Nr of actors/actresses:\", len(sub))\n",
    "    print(\"  Sample actors:\", [a for a in sub['name'].head(5)])\n",
    "\n",
    "print('-------------------------------------')\n",
    "for tier in sorted(centrality_df['tier_label_comb'].unique()):\n",
    "    sub = centrality_df[centrality_df['tier_label_comb'] == tier]\n",
    "    print(f\"Tier based PageRank & Eigenvector {tier}:\")\n",
    "    print(\"  Avg PageRank:\", round(sub['pagerank'].mean(), 7))\n",
    "    print(\"  Avg Eigenvector:\", round(sub['eigenvector'].mean(), 7))\n",
    "    print(\"  Avg Page + Eigen:\", round(sub['page_plus_eigen_scaled'].mean(), 4))\n",
    "    print(\"  Median Nr of Degrees:\", round(sub['degree'].median(), 2))\n",
    "    print(\"  Avg Nr of Degrees:\", round(sub['degree'].mean(), 2))\n",
    "    print(\"  Nr of actors/actresses:\", len(sub))\n",
    "    print(\"  Sample actors:\", [a for a in sub['name'].head(5)])"
   ],
   "id": "ec2ad3bac9562f06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(centrality_df.loc[\n",
    "    (centrality_df['tier_label_comb'] == 'A-list')\n",
    "].sort_values('page_plus_eigen_scaled', ascending=False).head(3).index)\n",
    "\n",
    "print(centrality_df.loc[\n",
    "    (centrality_df['tier_label_comb'] == 'B-list')\n",
    "].sort_values('page_plus_eigen_scaled', ascending=False).head(3).index)\n",
    "\n",
    "print(centrality_df.loc[\n",
    "    (centrality_df['tier_label_comb'] == 'C-list')\n",
    "].sort_values('page_plus_eigen_scaled', ascending=False).head(3).index)\n",
    "\n",
    "print(centrality_df.loc[\n",
    "    (centrality_df['tier_label_comb'] == 'D-list')\n",
    "].sort_values('page_plus_eigen_scaled', ascending=False).head(3).index)"
   ],
   "id": "94794ae4ecb74130"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eric_roberts_node = centrality_df[centrality_df['name'] == 'Eric Roberts'].index[0]\n",
    "# Get the ego graph for Eric Roberts with immediate neighbors\n",
    "ego_graph = nx.ego_graph(G_collabs, eric_roberts_node, radius=1, center=True, undirected=True)\n",
    "\n",
    "# Filter edges to include only those connected to Eric Roberts\n",
    "filtered_edges = [(eric_roberts_node, neighbor) for neighbor in ego_graph.neighbors(eric_roberts_node)]\n",
    "filtered_weights = [ego_graph[eric_roberts_node][neighbor]['weight'] for neighbor in ego_graph.neighbors(eric_roberts_node)]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(60, 50))\n",
    "pos = nx.spring_layout(ego_graph, k=0.5, seed=42, weight='weight')\n",
    "# Define a color map for tiers\n",
    "tier_colors = {\n",
    "    'A-list': 'gold',\n",
    "    'B-list': 'silver',\n",
    "    'C-list': 'lightblue',\n",
    "    'D-list': 'gray'\n",
    "}\n",
    "# Get the tier for each node\n",
    "node_colors = [\n",
    "    tier_colors[centrality_df.loc[node, 'tier_label_comb']]\n",
    "    if node in centrality_df.index else 'gray'\n",
    "    for node in ego_graph.nodes()\n",
    "]\n",
    "options = {\n",
    "    \"node_color\": node_colors,\n",
    "    \"edge_color\": filtered_weights,\n",
    "    \"edgelist\": filtered_edges,\n",
    "    \"edge_cmap\": plt.cm.Reds,\n",
    "    \"with_labels\": True,\n",
    "    \"labels\": {n: G_collabs.nodes[n]['name'] for n in ego_graph.nodes()},\n",
    "    \"node_size\": 1000,\n",
    "    \"font_size\": 10\n",
    "}\n",
    "print(f\"Number of nodes in the graph: {ego_graph.number_of_nodes()}\")\n",
    "nx.draw(ego_graph, pos, **options)\n",
    "plt.title(\"Eric Roberts' Closest Neighbors (Tier Colors)\")\n",
    "plt.show()\n"
   ],
   "id": "d2a089a112459ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "actor_name = 'Bill Barretta'\n",
    "actor_info = centrality_df[centrality_df['name'] == actor_name]\n",
    "actor_info[['pagerank', 'eigenvector', 'degree', 'tier_label_pr', 'tier_label_ev', 'tier_label_comb']]"
   ],
   "id": "961107a950fa501f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_movies_by_actor(actor_name, df):\n",
    "    # Filter rows where the actor appears\n",
    "    actor_movies = df[df['actor_name'] == actor_name]\n",
    "    # Select relevant columns (e.g., movie title, average rating, year)\n",
    "    return actor_movies[['movie_title', 'average_rating', 'start_year']].drop_duplicates()\n",
    "\n",
    "# Example usage\n",
    "actor_name = \"Eric Roberts\"\n",
    "movies = get_movies_by_actor(actor_name, df)\n",
    "print(f\"Movies of {actor_name}:\")\n",
    "movies"
   ],
   "id": "4dcb5ccae50f14aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_movies_by_actor_pair(actor1, actor2, df):\n",
    "    # Filter rows where both actors appear in the same movie\n",
    "    movies_together = df[df['actor_name'].isin([actor1, actor2])]\n",
    "    movies_together = movies_together.groupby('tconst').filter(lambda x: len(x['actor_name'].unique()) > 1)\n",
    "    return movies_together[['tconst', 'movie_title', 'average_rating']].drop_duplicates()\n",
    "\n",
    "# Example usage\n",
    "actor1 = \"Eric Roberts\"\n",
    "actor2 = \"John Schneider\"\n",
    "# Get movies where both actors appeared together\n",
    "movies = get_movies_by_actor_pair(actor1, actor2, df)\n",
    "print(movies)"
   ],
   "id": "5c66404f86addea2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "edge_rows = []\n",
    "\n",
    "for i in range(len(filtered_edges)):\n",
    "    u, v = filtered_edges[i]\n",
    "    value = filtered_weights[i]\n",
    "    edge_rows.append(f\"{u};{v};{value}\")\n",
    "\n",
    "with open(\"edges.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"source;target;value\\n\")\n",
    "    f.write(\"\\n\".join(edge_rows))\n",
    "\n",
    "node_rows = []\n",
    "\n",
    "for node, data in ego_graph.nodes(data=True):\n",
    "    category = data.get('tier_label_comb')\n",
    "    name = data.get('name')\n",
    "    node_rows.append(f\"{node};{name};{category}\")\n",
    "\n",
    "with open(\"nodes.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"id;name;category\\n\")\n",
    "    f.write(\"\\n\".join(node_rows))"
   ],
   "id": "7e3aa22b70fbe422"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='eric roberts ego graph.png')"
   ],
   "id": "cb07ff5d583dcab7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Star power graph",
   "id": "44ff0cdcc7c0e50c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import networkx as nx\n",
    "from itertools import combinations\n",
    "\n",
    "G_starPower = nx.Graph()\n",
    "\n",
    "for tconst, group in df.groupby('tconst'):\n",
    "    actors = group['actor_name'].tolist()\n",
    "    avg_rating = group['average_rating'].iloc[0]\n",
    "    num_votes = group['num_votes'].iloc[0] \n",
    "    for actor1, actor2 in combinations(actors, 2):\n",
    "        if actor1 == actor2:\n",
    "            continue\n",
    "        # Add nodes excplicitly to add name attributes\n",
    "        if not G_starPower.has_node(actor1):\n",
    "            G_starPower.add_node(actor1, name=actor1)\n",
    "        if not G_starPower.has_node(actor2):\n",
    "            G_starPower.add_node(actor2, name=actor2)\n",
    "        # Add edge with weight\n",
    "        if G_starPower.has_edge(actor1, actor2):\n",
    "            # Update total weighted rating and movie count\n",
    "            G_starPower[actor1][actor2]['movie_count'] += 1\n",
    "            # Update the weighted average rating\n",
    "            G_starPower[actor1][actor2]['weight'] += avg_rating * num_votes\n",
    "        else:\n",
    "             # Initialize edge attributes\n",
    "            G_starPower.add_edge(\n",
    "                actor1, actor2,\n",
    "                movie_count=1,\n",
    "                weight=avg_rating * num_votes \n",
    "            )"
   ],
   "id": "2b23a1593aa2a5d6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pagerank = nx.pagerank(G_starPower, weight='weight')\n",
    "nx.set_node_attributes(G_starPower, pagerank, name='pagerank')\n",
    "\n",
    "eigen_centrality = nx.eigenvector_centrality(G_starPower, max_iter=1000, weight='weight')\n",
    "nx.set_node_attributes(G_starPower, eigen_centrality, name='eigen_centrality')"
   ],
   "id": "6ebbda12b1d7ca5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "centrality_df = pd.DataFrame.from_dict(pagerank, orient='index', columns=['pagerank'])\n",
    "centrality_df['eigenvector'] = pd.Series(eigen_centrality)\n",
    "# Scale pagerank to range [0, 0.5]\n",
    "pagerank_scaler = MinMaxScaler(feature_range=(0, 0.5))\n",
    "centrality_df['pagerank_scaled'] = pagerank_scaler.fit_transform(centrality_df[['pagerank']])\n",
    "# Scale eigenvector centrality to range [0, 0.5]\n",
    "eigenvector_scaler = MinMaxScaler(feature_range=(0, 0.5))\n",
    "centrality_df['eigenvector_scaled'] = eigenvector_scaler.fit_transform(centrality_df[['eigenvector']])\n",
    "# Combine scaled pagerank and eigenvector centrality\n",
    "centrality_df['page_plus_eigen_scaled'] = centrality_df['pagerank_scaled'] + centrality_df['eigenvector_scaled']\n",
    "\n",
    "degree_dict = dict(G_starPower.degree())  # Unweighted degree — just the number of neighbors\n",
    "centrality_df['degree'] = pd.Series(degree_dict)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# KMEANS clustering on pagerank\n",
    "X = scaler.fit_transform(centrality_df[['pagerank']])\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "centrality_df['tier_page'] = kmeans.fit_predict(X)\n",
    "\n",
    "# KMEANS clustering on eigenvector centrality\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(centrality_df[['eigenvector']])\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "centrality_df['tier_eigen'] = kmeans.fit_predict(X)\n",
    "\n",
    "#KMEANS clustering on pagerank + eigenvector centrality\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(centrality_df[['page_plus_eigen_scaled']])\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "centrality_df['tier_combined'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Map sorted cluster index to labels to have meaningful names\n",
    "labels = ['A-list', 'B-list', 'C-list', 'D-list']\n",
    "tier_means = centrality_df.groupby('tier_page')['pagerank'].mean().sort_values(ascending=False)\n",
    "tier_to_label = {tier: label for tier, label in zip(tier_means.index, labels)}\n",
    "\n",
    "centrality_df['tier_label_pr'] = centrality_df['tier_page'].map(tier_to_label)\n",
    "nx.set_node_attributes(G_starPower, centrality_df['tier_label_pr'].to_dict(), name='tier_label_pr')\n",
    "\n",
    "labels = ['A-list', 'B-list', 'C-list', 'D-list']\n",
    "tier_means = centrality_df.groupby('tier_eigen')['eigenvector'].mean().sort_values(ascending=False)\n",
    "tier_to_label = {tier: label for tier, label in zip(tier_means.index, labels)}\n",
    "\n",
    "centrality_df['tier_label_ev'] = centrality_df['tier_eigen'].map(tier_to_label)\n",
    "nx.set_node_attributes(G_starPower, centrality_df['tier_label_ev'].to_dict(), name='tier_label_ev')\n",
    "\n",
    "labels = ['A-list', 'B-list', 'C-list', 'D-list']\n",
    "tier_means = centrality_df.groupby('tier_combined')['page_plus_eigen_scaled'].mean().sort_values(ascending=False)\n",
    "tier_to_label = {tier: label for tier, label in zip(tier_means.index, labels)}\n",
    "\n",
    "centrality_df['tier_label_comb'] = centrality_df['tier_combined'].map(tier_to_label)\n",
    "nx.set_node_attributes(G_starPower, centrality_df['tier_label_comb'].to_dict(), name='tier_label_comb')"
   ],
   "id": "ca6703a05db687a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Merge the centrality_df with the original df to include average_rating\n",
    "df_with_tiers = df.copy().merge(centrality_df[['tier_label_comb']], left_on='actor_name', right_index=True, how='inner')\n",
    "\n",
    "# Group by tier and calculate the average rating\n",
    "tier_avg_rating = df_with_tiers.groupby('tier_label_comb')['average_rating'].mean()\n",
    "\n",
    "# Print the average rating for each tier\n",
    "print(\"Average rating by tier:\")\n",
    "print(tier_avg_rating)"
   ],
   "id": "ef599ca3ba584d16"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "centrality_df['name'] = centrality_df.index.map(lambda node: G_starPower.nodes[node]['name'])\n",
    "\n",
    "for tier in sorted(centrality_df['tier_label_pr'].unique()):\n",
    "    sub = centrality_df[centrality_df['tier_label_pr'] == tier]\n",
    "    print(f\"Tier based on PageRank {tier}:\")\n",
    "    print(\"  Avg PageRank:\", round(sub['pagerank'].mean(), 7))\n",
    "    print(\"  Avg Eigenvector:\", round(sub['eigenvector'].mean(), 7))\n",
    "    print(\"  Avg Page + Eigen:\", round(sub['page_plus_eigen_scaled'].mean(), 4))\n",
    "    print(\"  Avg Nr of Degrees:\", round(sub['degree'].mean(), 2))\n",
    "    print(\"  Median Nr of Degrees:\", round(sub['degree'].median(), 2))\n",
    "    print(\"  Nr of actors/actresses:\", len(sub))\n",
    "    print(\"  Sample actors:\", [a for a in sub['name'].head(5)])\n",
    "\n",
    "print('-------------------------------------')\n",
    "for tier in sorted(centrality_df['tier_label_ev'].unique()):\n",
    "    sub = centrality_df[centrality_df['tier_label_ev'] == tier]\n",
    "    print(f\"Tier based on Eigenvector {tier}:\")\n",
    "    print(\"  Avg PageRank:\", round(sub['pagerank'].mean(), 7))\n",
    "    print(\"  Avg Eigenvector:\", round(sub['eigenvector'].mean(), 7))\n",
    "    print(\"  Avg Page + Eigen:\", round(sub['page_plus_eigen_scaled'].mean(), 4))\n",
    "    print(\"  Avg Nr of Degrees:\", round(sub['degree'].mean(), 2))\n",
    "    print(\"  Median Nr of Degrees:\", round(sub['degree'].median(), 2))\n",
    "    print(\"  Nr of actors/actresses:\", len(sub))\n",
    "    print(\"  Sample actors:\", [a for a in sub['name'].head(5)])\n",
    "\n",
    "print('-------------------------------------')\n",
    "for tier in sorted(centrality_df['tier_label_comb'].unique()):\n",
    "    sub = centrality_df[centrality_df['tier_label_comb'] == tier]\n",
    "    print(f\"Tier based PageRank & Eigenvector {tier}:\")\n",
    "    print(\"  Avg PageRank:\", round(sub['pagerank'].mean(), 7))\n",
    "    print(\"  Avg Eigenvector:\", round(sub['eigenvector'].mean(), 7))\n",
    "    print(\"  Avg Page + Eigen:\", round(sub['page_plus_eigen_scaled'].mean(), 4))\n",
    "    print(\"  Median Nr of Degrees:\", round(sub['degree'].median(), 2))\n",
    "    print(\"  Avg Nr of Degrees:\", round(sub['degree'].mean(), 2))\n",
    "    print(\"  Nr of actors/actresses:\", len(sub))\n",
    "    print(\"  Sample actors:\", [a for a in sub['name'].head(5)])"
   ],
   "id": "b55f9647056ecd38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(centrality_df.loc[\n",
    "    (centrality_df['tier_label_comb'] == 'A-list')\n",
    "].sort_values('page_plus_eigen_scaled', ascending=False).head(3).index)\n",
    "\n",
    "print(centrality_df.loc[\n",
    "    (centrality_df['tier_label_comb'] == 'B-list')\n",
    "].sort_values('page_plus_eigen_scaled', ascending=False).head(3).index)\n",
    "\n",
    "print(centrality_df.loc[\n",
    "    (centrality_df['tier_label_comb'] == 'C-list')\n",
    "].sort_values('page_plus_eigen_scaled', ascending=False).head(3).index)\n",
    "\n",
    "print(centrality_df.loc[\n",
    "    (centrality_df['tier_label_comb'] == 'D-list')\n",
    "].sort_values('page_plus_eigen_scaled', ascending=False).head(3).index)"
   ],
   "id": "e1366607fa4e65fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_a_list_actors_comb = centrality_df.loc[\n",
    "    (centrality_df['tier_label_comb'] == 'A-list')\n",
    "].sort_values('page_plus_eigen_scaled', ascending=False).head(5).index\n",
    "print(f\"Top A-list actor: {centrality_df.loc[top_a_list_actors_comb[0]]}\")\n",
    "# Expand the subgraph to include all neighbors of the top A-list actors\n",
    "expanded_nodes = set()\n",
    "filtered_edges = []\n",
    "filtered_weights = []\n",
    "\n",
    "for actor in top_a_list_actors_comb:\n",
    "    ego_graph = nx.ego_graph(G_starPower, actor, radius=1, center=True, undirected=True)\n",
    "    expanded_nodes.update(ego_graph.nodes)\n",
    "    # Filter edges to include only those connected to the top A-list actors\n",
    "    for neighbor in ego_graph.neighbors(actor):\n",
    "        filtered_edges.append((actor, neighbor))\n",
    "        filtered_weights.append(ego_graph[actor][neighbor]['weight'])\n",
    "\n",
    "# Create a subgraph with the expanded nodes\n",
    "H = G_starPower.copy().subgraph(expanded_nodes)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(25, 20))\n",
    "pos = nx.random_layout(H, seed=42)\n",
    "# Define a color map for tiers\n",
    "tier_colors = {\n",
    "    'A-list': 'gold',\n",
    "    'B-list': 'silver',\n",
    "    'C-list': 'lightblue',\n",
    "    'D-list': 'gray'\n",
    "}\n",
    "# Get the tier for each node\n",
    "node_colors = [\n",
    "    tier_colors[centrality_df.loc[node, 'tier_label_comb']]\n",
    "    if node in centrality_df.index else 'gray'\n",
    "    for node in H.nodes()\n",
    "]\n",
    "options = {\n",
    "    \"node_color\": node_colors,\n",
    "    \"edge_color\": filtered_weights,\n",
    "    \"edgelist\": filtered_edges,\n",
    "    \"edge_cmap\": plt.cm.Reds,\n",
    "    \"with_labels\": True,\n",
    "    \"labels\": {n: G_starPower.nodes[n]['name'] for n in H.nodes()},\n",
    "    \"font_size\": 10\n",
    "}\n",
    "nx.draw(H, pos, **options)\n",
    "plt.title(\"A-list Actors' Closest Neighbors (Tier Colors)\")\n",
    "plt.show()\n"
   ],
   "id": "e6bed94ab0b81eae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Saving edges and nodes to CSV files for visualization\n",
    "edge_rows = []\n",
    "\n",
    "for i in range(len(filtered_edges)):\n",
    "    u, v = filtered_edges[i]\n",
    "    value = filtered_weights[i] \n",
    "    edge_rows.append(f\"{u};{v};{value}\")\n",
    "\n",
    "with open(\"edges.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"source;target;value\\n\")\n",
    "    f.write(\"\\n\".join(edge_rows))\n",
    "\n",
    "node_rows = []\n",
    "\n",
    "for node, data in H.nodes(data=True):\n",
    "    category = data.get('tier_label_comb')\n",
    "    name = data.get('name')\n",
    "    node_rows.append(f\"{node};{name};{category}\")\n",
    "\n",
    "with open(\"nodes.csv\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"id;name;category\\n\")\n",
    "    f.write(\"\\n\".join(node_rows))"
   ],
   "id": "68882bf12a313970"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='star power top5 graph.PNG')"
   ],
   "id": "96a568047b6fcd31"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "movies = get_movies_by_actor_pair(\"Dee Wallace\", \"Robert Miano\", df)\n",
    "print(movies)"
   ],
   "id": "b7b0a84869b5878f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Group by actor_name and calculate the average rating\n",
    "actor_avg_ratings = df.groupby('actor_name')['average_rating'].mean()\n",
    "\n",
    "# Find the actor with the maximum average rating\n",
    "max_rating_actor = actor_avg_ratings.idxmax()  # Actor with the highest average rating\n",
    "max_rating = actor_avg_ratings.max()  # Maximum average rating\n",
    "\n",
    "print(f\"Actor with the highest average rating: {max_rating_actor} ({max_rating:.2f}), nr of movies: {len(df[df['actor_name'] == max_rating_actor])}\")\n",
    "print(f\"Actor's tier based on PageRank and Eigenvector: {centrality_df.loc[max_rating_actor, 'tier_label_comb']}\")"
   ],
   "id": "360672a1773d5c8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_actor_average_rating(actor_name, df):\n",
    "    # Filter the DataFrame for movies where the actor appears\n",
    "    actor_movies = df[df['actor_name'] == actor_name]\n",
    "    \n",
    "    # Calculate the average rating\n",
    "    avg_rating = actor_movies['average_rating'].mean()\n",
    "    \n",
    "    # Count the number of movies\n",
    "    num_movies = actor_movies['tconst'].nunique() \n",
    "    \n",
    "    return avg_rating, num_movies\n",
    "\n",
    "actor_name = \"Scarlett Johansson\"\n",
    "avg_rating, num_movies = get_actor_average_rating(actor_name, df)\n",
    "\n",
    "print(f\"Average rating of movies for {actor_name}: {avg_rating:.2f}\")\n",
    "print(f\"Number of movies for {actor_name}: {num_movies}\")"
   ],
   "id": "466683cfbe9d43dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Bipartite graph between actors and genres",
   "id": "9a88d24284763720"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a bipartite graph\n",
    "B = nx.Graph()\n",
    "\n",
    "# Iterate through the DataFrame to add nodes and edges\n",
    "for _, row in df.iterrows():\n",
    "    actor = row['actor_name']\n",
    "    genres = row['genres']\n",
    "    movie_title = row['movie_title']\n",
    "    avg_rating = row['average_rating']\n",
    "    num_votes = row['num_votes']\n",
    "    \n",
    "    # Add actor node (part of set 0)\n",
    "    if not B.has_node(actor):\n",
    "        B.add_node(actor, bipartite=0, type='actor')  # Add type attribute for clarity\n",
    "    \n",
    "    # Add genre nodes (part of set 1) and edges\n",
    "    for genre in genres:\n",
    "        if not B.has_node(genre):\n",
    "            B.add_node(genre, bipartite=1, type='genre')  # Add type attribute for clarity\n",
    "        \n",
    "        # Add edge between actor and genre with movie attributes\n",
    "        if not B.has_edge(actor, genre):\n",
    "            B.add_edge(actor, genre, movies=[movie_title], total_rating=avg_rating, total_votes=num_votes, weight=avg_rating * num_votes)\n",
    "        else:\n",
    "            # Update edge attributes if the edge already exists\n",
    "            B[actor][genre]['movies'].append(movie_title)\n",
    "            B[actor][genre]['total_rating'] += avg_rating\n",
    "            B[actor][genre]['total_votes'] += num_votes\n",
    "            B[actor][genre]['weight'] = B[actor][genre]['total_rating'] * B[actor][genre]['total_votes'] * len(B[actor][genre]['movies'])\n",
    "\n",
    "print(f\"Number of nodes: {B.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {B.number_of_edges()}\")"
   ],
   "id": "4c4e7b4e17f5da00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "actor_movie_counts = df.groupby('actor_name')['tconst'].nunique()  # Count unique movies per actor\n",
    "actors_with_multiple_movies = actor_movie_counts[actor_movie_counts > 5].index  # Get actors with more than 5 movie\n",
    "\n",
    "# Filter the bipartite graph to include only these actors\n",
    "filtered_B = B.copy().subgraph([node for node in B.nodes if B.nodes[node]['type'] == 'genre' or node in actors_with_multiple_movies])\n",
    "\n",
    "# Filter actor nodes (bipartite=0) and calculate their degree (connections to genres)\n",
    "actor_genre_degrees = {\n",
    "    node: len([neighbor for neighbor in filtered_B.neighbors(node) if filtered_B.nodes[neighbor]['type'] == 'genre'])\n",
    "    for node, data in filtered_B.nodes(data=True) if data['type'] == 'actor'\n",
    "}\n",
    "\n",
    "# Sort actors by the number of genre connections\n",
    "sorted_actor_genre_degrees = sorted(actor_genre_degrees.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get the top 5 actors with the most genre connections\n",
    "top_5_most_genres = sorted_actor_genre_degrees[:5]\n",
    "\n",
    "# Get the top 5 actors with the least genre connections\n",
    "top_5_least_genres = sorted_actor_genre_degrees[-5:]\n",
    "\n",
    "print(\"Top 5 actors with the most genre connections:\")\n",
    "for actor, count in top_5_most_genres:\n",
    "    print(f\"{actor}: {count} genres\")\n",
    "\n",
    "print(\"\\nTop 5 actors with the least genre connections:\")\n",
    "for actor, count in top_5_least_genres:\n",
    "    print(f\"{actor}: {count} genres\")"
   ],
   "id": "c3805cc5d973b0e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#df.drop(columns=['weighted_avg_rating'], inplace=True)\n",
    "df['weighted_avg_rating'] = df['average_rating'] * df['num_votes']  # Weighted rating\n",
    "# Calculate the average weighted rating for each actor\n",
    "actor_avg_ratings = df.groupby('actor_name')[['weighted_avg_rating', 'average_rating']].mean()\n",
    "# Sort actors by their average rating in descending order\n",
    "sorted_actor_avg_ratings = actor_avg_ratings.sort_values(by='weighted_avg_rating', ascending=False)['average_rating']\n",
    "# Get the top 5 highest-rated actors\n",
    "top_5_highest_rated_actors = sorted_actor_avg_ratings.head(5)\n",
    "\n",
    "print(\"Top 5 highest-rated actors across all genres:\")\n",
    "for actor, avg_rating in top_5_highest_rated_actors.items():\n",
    "    print(f\"{actor}: {avg_rating:.2f}\")\n",
    "\n",
    "print(\"\\nTop 5 lowest-rated actors across all genres:\")\n",
    "for actor, avg_rating in sorted_actor_avg_ratings[-5:].items():\n",
    "    print(f\"{actor}: {avg_rating:.2f}\")"
   ],
   "id": "3de57de305c5bcad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_actor_best_and_worst_genres(actor_name, df):\n",
    "    # Filter the DataFrame for movies where the actor appears\n",
    "    actor_movies = df[df['actor_name'] == actor_name]\n",
    "    \n",
    "    # Dictionary to store average ratings for each genre\n",
    "    genre_ratings = defaultdict(list)\n",
    "    \n",
    "    # Iterate through the actor's movies and collect ratings for each genre\n",
    "    for _, row in actor_movies.iterrows():\n",
    "        genres = row['genres']\n",
    "        for genre in genres:\n",
    "            genre_ratings[genre].append(row['average_rating'])\n",
    "    \n",
    "    # Calculate the average rating for each genre\n",
    "    avg_genre_ratings = {genre: sum(ratings) / len(ratings) for genre, ratings in genre_ratings.items()}\n",
    "    \n",
    "    # Find the best and worst genres\n",
    "    best_genre = max(avg_genre_ratings, key=avg_genre_ratings.get)\n",
    "    worst_genre = min(avg_genre_ratings, key=avg_genre_ratings.get)\n",
    "    \n",
    "    return best_genre, avg_genre_ratings[best_genre], worst_genre, avg_genre_ratings[worst_genre]\n",
    "\n",
    "actor_name = \"Scarlett Johansson\"\n",
    "best_genre, best_rating, worst_genre, worst_rating = get_actor_best_and_worst_genres(actor_name, df)\n",
    "\n",
    "print(f\"Best genre for {actor_name}: {best_genre} ({best_rating:.2f})\")\n",
    "print(f\"Worst genre for {actor_name}: {worst_genre} ({worst_rating:.2f})\")"
   ],
   "id": "b0de755af46d73bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "actor_movie_counts = df.groupby('actor_name')['tconst'].nunique()  # Count unique movies per actor\n",
    "\n",
    "filtered_B = B.copy().subgraph([node for node in B.nodes if B.nodes[node]['type'] == 'genre' or node in actor_movie_counts])\n",
    "actor_genre_degrees = {\n",
    "    node: len([neighbor for neighbor in filtered_B.neighbors(node) if filtered_B.nodes[neighbor]['type'] == 'genre'])\n",
    "    for node, data in filtered_B.nodes(data=True) if data['type'] == 'actor'\n",
    "}\n",
    "# Count the frequency of genre connections\n",
    "genre_connection_counts = Counter(actor_genre_degrees.values())\n",
    "\n",
    "# Sort the counts by the number of genre connections\n",
    "sorted_genre_counts = sorted(genre_connection_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "# Separate the data for plotting\n",
    "genre_counts, actor_frequencies = zip(*sorted_genre_counts)\n",
    "# Calculate percentages\n",
    "total_actors = sum(actor_frequencies)\n",
    "actor_percentages = [(freq / total_actors) * 100 for freq in actor_frequencies]\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(9, 6))\n",
    "bars = plt.bar(genre_counts, actor_percentages, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "# Add percentage labels on top of each bar\n",
    "for bar, percentage in zip(bars, actor_percentages):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,  # X-coordinate (center of the bar)\n",
    "        bar.get_height() + 0.5,            # Y-coordinate (slightly above the bar)\n",
    "        f\"{percentage:.2f}%\",             # Text to display\n",
    "        ha='center', va='bottom', fontsize=14  # Center alignment\n",
    "    )\n",
    "\n",
    "plt.title(\"Distribution of Top 10 Genre Connections Among Actors\", fontsize=18)\n",
    "plt.xlabel(\"Number of Genre Connections\", fontsize=14)\n",
    "plt.ylabel(\"Percentage of Actors (%)\", fontsize=14)\n",
    "plt.xticks(range(min(genre_counts), 11), fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "92c2bc458848d64d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_actor_genre_connections(actor_name, graph):\n",
    "    # Check if the actor exists in the graph\n",
    "    if actor_name not in graph:\n",
    "        print(f\"Actor '{actor_name}' not found in the graph.\")\n",
    "        return []\n",
    "    \n",
    "    # Get all neighbors of the actor and filter for genres\n",
    "    genre_connections = [neighbor for neighbor in graph.neighbors(actor_name) if graph.nodes[neighbor]['type'] == 'genre']\n",
    "    \n",
    "    return genre_connections\n",
    "\n",
    "actor_name = \"Eric Roberts\"\n",
    "genre_connections = get_actor_genre_connections(actor_name, B)\n",
    "\n",
    "print(f\"Genres connected to {actor_name}: {genre_connections}\")"
   ],
   "id": "8acc27a4441d0149"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Count the occurrences of each genre\n",
    "genre_counts = Counter()\n",
    "for genres in df['genres']:\n",
    "    genre_counts.update(genres)\n",
    "\n",
    "# Sort genres by their counts\n",
    "sorted_genre_counts = sorted(genre_counts.items(), key=lambda x: x[1], reverse=True)[:10]  # Get top 10 genres\n",
    "\n",
    "# Separate data for plotting\n",
    "genres, counts = zip(*sorted_genre_counts)\n",
    "# Calculate percentages\n",
    "total_genres = sum(counts)\n",
    "genre_percentages = [(freq / total_genres) * 100 for freq in counts]\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "bars = plt.bar(genres, genre_percentages, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "for bar, percentage in zip(bars, genre_percentages):\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width() / 2,  # X-coordinate (center of the bar)\n",
    "        bar.get_height() + 0.5,            # Y-coordinate (slightly above the bar)\n",
    "        f\"{percentage:.2f}%\",             # Text to display\n",
    "        ha='center', va='bottom', fontsize=12  # Center alignment\n",
    "    )\n",
    "plt.title(\"Popularity of Genres Top 10\", fontsize=18)\n",
    "plt.xlabel(\"Genres\", fontsize=14)\n",
    "plt.ylabel(\"Percentage of Appearances (%)\", fontsize=14)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=12)  # Rotate x-axis labels for better readability\n",
    "plt.yticks(fontsize=12) \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "d28a659bfd410c3d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "genre_nodes = [n for n, d in B.nodes(data=True) if d.get('type') == 'genre']\n",
    "\n",
    "# For each genre, collect connected actors and their edge weights\n",
    "top_actors_per_genre = {}\n",
    "\n",
    "for genre in genre_nodes:\n",
    "    neighbors = B.neighbors(genre)\n",
    "    actor_movie_counts = []\n",
    "\n",
    "    for actor in neighbors:\n",
    "        edge_data = B.get_edge_data(genre, actor)\n",
    "        movies = edge_data.get('movies', [])  # Ensure it's a list\n",
    "        movie_count = len(movies)\n",
    "        actor_movie_counts.append((actor, movie_count, movies))\n",
    "\n",
    "    # Sort actors by movie count and get top 5\n",
    "    top_5 = sorted(actor_movie_counts, key=lambda x: x[1], reverse=True)[:5]\n",
    "    top_actors_per_genre[genre] = top_5\n",
    "\n",
    "for genre, actor_info in top_actors_per_genre.items():\n",
    "    print(f\"\\n Top 5 actors for genre '{genre}':\")\n",
    "    for actor, count, movies in actor_info:\n",
    "        print(f\"  {actor} — {count} movies\")"
   ],
   "id": "42fbadf12656f4ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def find_niche_actors_with_graph(graph):\n",
    "    # List to store niche actors\n",
    "    niche_actors = []\n",
    "\n",
    "    # Filter actor nodes\n",
    "    actor_nodes = [node for node, data in graph.nodes(data=True) if data['type'] == 'actor']\n",
    "\n",
    "    for actor in actor_nodes:\n",
    "        # Get all genres connected to the actor\n",
    "        genre_edges = [(genre, graph[actor][genre]) for genre in graph.neighbors(actor) if graph.nodes[genre]['type'] == 'genre']\n",
    "\n",
    "        # Calculate the total number of movies for the actor\n",
    "        total_movies = sum(len(edge_data['movies']) for _, edge_data in genre_edges)\n",
    "        if total_movies <= 10: # to filter out actors with too few movies\n",
    "            continue\n",
    "        # Count the number of movies for each genre\n",
    "        genre_counts = {genre: len(edge_data['movies']) for genre, edge_data in genre_edges}\n",
    "\n",
    "        # Find the most frequent genre and its count\n",
    "        most_frequent_genre = max(genre_counts, key=genre_counts.get)\n",
    "        most_frequent_genre_count = genre_counts[most_frequent_genre]\n",
    "\n",
    "        # Check if the most frequent genre accounts for at least 75% of the movies\n",
    "        if most_frequent_genre_count > total_movies * 0.75:\n",
    "            niche_actors.append({\n",
    "                'actor': actor,\n",
    "                'total_movies': total_movies,\n",
    "                'most_frequent_genre': most_frequent_genre,\n",
    "                'genre_count': most_frequent_genre_count,\n",
    "                'ratio': most_frequent_genre_count / total_movies\n",
    "            })\n",
    "\n",
    "    return sorted(niche_actors, key=lambda x: x['ratio'], reverse=True)\n",
    "\n",
    "niche_actors = find_niche_actors_with_graph(B.copy())\n",
    "\n",
    "print(\"Niche actors:\")\n",
    "for actor_info in niche_actors:\n",
    "    print(f\"Actor: {actor_info['actor']}, Total Movies: {actor_info['total_movies']}, \"\n",
    "          f\"Most Frequent Genre: {actor_info['most_frequent_genre']} ({actor_info['genre_count']} movies) {actor_info['ratio']:.2%} of all movies)\")"
   ],
   "id": "67dd6637ad8ac59f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Clustering on bipartite graph",
   "id": "451342b0a52af7b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.cluster import SpectralCoclustering\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Filter actor and genre nodes\n",
    "actor_nodes = [node for node, data in B.nodes(data=True) if data['type'] == 'actor']\n",
    "genre_nodes = [node for node, data in B.nodes(data=True) if data['type'] == 'genre']\n",
    "\n",
    "# Create the bipartite adjacency matrix\n",
    "adj_matrix = nx.bipartite.biadjacency_matrix(B, row_order=actor_nodes, column_order=genre_nodes)\n",
    "\n",
    "# Apply Spectral Co-clustering\n",
    "model = SpectralCoclustering(n_clusters=9, random_state=0)  # Adjust n_clusters as needed\n",
    "model.fit(adj_matrix)\n",
    "\n",
    "# Extract clusters\n",
    "actor_clusters = model.row_labels_  # Cluster labels for actors\n",
    "genre_clusters = model.column_labels_  # Cluster labels for genres\n",
    "\n",
    "# Map clusters back to actor and genre names\n",
    "actor_cluster_mapping = {actor: cluster for actor, cluster in zip(actor_nodes, actor_clusters)}\n",
    "genre_cluster_mapping = {genre: cluster for genre, cluster in zip(genre_nodes, genre_clusters)}\n",
    "\n",
    "'''\n",
    "print(\"Actor Clusters:\")\n",
    "for actor, cluster in actor_cluster_mapping.items():\n",
    "    print(f\"  Actor: {actor}, Cluster: {cluster}\")\n",
    "\n",
    "print(\"\\nGenre Clusters:\")\n",
    "for genre, cluster in genre_cluster_mapping.items():\n",
    "    print(f\"  Genre: {genre}, Cluster: {cluster}\")\n",
    "'''"
   ],
   "id": "2f29071c70436a74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Group actors and genres by cluster\n",
    "actor_clusters_by_id = defaultdict(list)\n",
    "genre_clusters_by_id = defaultdict(list)\n",
    "\n",
    "for actor, cluster in actor_cluster_mapping.items():\n",
    "    actor_clusters_by_id[cluster].append(actor)\n",
    "\n",
    "for genre, cluster in genre_cluster_mapping.items():\n",
    "    genre_clusters_by_id[cluster].append(genre)\n",
    "\n",
    "for i in range(9):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "    print(f\"  Actors: {actor_clusters_by_id[i][:5]}\")  # Show only top 5 actors in each cluster\n",
    "    print(f\"  Genres: {genre_clusters_by_id[i]}\")"
   ],
   "id": "fd48254f19bc223"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!pip install scipy",
   "id": "70e7aea46d5134e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import networkx as nx\n",
    "from sklearn.decomposition import NMF\n",
    "from scipy.sparse import csr_matrix\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 1: Filter actor and genre nodes\n",
    "actor_nodes = [node for node, data in B.nodes(data=True) if data['type'] == 'actor']\n",
    "genre_nodes = [node for node, data in B.nodes(data=True) if data['type'] == 'genre']\n",
    "#actors_with_enough_movies = [actor for actor in actor_nodes if B.degree(actor) >= 5]\n",
    "# Step 2: Create the bipartite adjacency matrix\n",
    "adj_matrix = nx.bipartite.biadjacency_matrix(B, row_order=actor_nodes, column_order=genre_nodes)\n",
    "# Choose number of clusters\n",
    "n_clusters = 9\n",
    "\n",
    "# Run NMF\n",
    "nmf = NMF(n_components=n_clusters, init='nndsvda', random_state=42)\n",
    "W = nmf.fit_transform(adj_matrix)        # W: actors × components\n",
    "H = nmf.components_                      # H: components × genres\n",
    "\n",
    "# Assign actors and genres to clusters\n",
    "actor_clusters = W.argmax(axis=1)\n",
    "genre_clusters = H.argmax(axis=0)\n",
    "\n",
    "# Map back to names\n",
    "actor_cluster_mapping_nmf = {actor: cluster for actor, cluster in zip(actor_nodes, actor_clusters)}\n",
    "genre_cluster_mapping_nmf = {genre: cluster for genre, cluster in zip(genre_nodes, genre_clusters)}\n",
    "\n",
    "'''\n",
    "actor_total_ratings = {}\n",
    "for actor in actor_nodes:\n",
    "    total_rating = sum(B[actor][neighbor].get('weighted_avg_rating', 0) for neighbor in B.neighbors(actor))\n",
    "    actor_total_ratings[actor] = total_rating\n",
    "'''\n",
    "# Dictionary to store weighted average ratings for each actor by genre\n",
    "actor_genre_ratings = defaultdict(dict)\n",
    "\n",
    "# Iterate over all actor nodes\n",
    "for actor in actor_nodes:\n",
    "    for genre in B.neighbors(actor):\n",
    "        if B.nodes[genre]['type'] == 'genre':  # Ensure the neighbor is a genre\n",
    "            edge_data = B.get_edge_data(actor, genre)\n",
    "            actor_genre_ratings[actor][genre] = edge_data.get('weighted_avg_rating', 0)  # Weighted average rating from edge attributes\n",
    "\n",
    "# Group actors and genres by cluster\n",
    "actor_clusters_by_id = defaultdict(list)\n",
    "genre_clusters_by_id = defaultdict(list)\n",
    "\n",
    "for genre, cluster in genre_cluster_mapping_nmf.items():\n",
    "    genre_clusters_by_id[cluster].append(genre)\n",
    "\n",
    "# Group actors by cluster and calculate the max weighted average rating for genres in the cluster\n",
    "for actor, cluster in actor_cluster_mapping_nmf.items():\n",
    "    # Get the genres in the same cluster\n",
    "    genres_in_cluster = genre_clusters_by_id[cluster]\n",
    "    \n",
    "    # Calculate the max weighted average rating for the actor across genres in the cluster\n",
    "    max_weighted_avg_rating = 0\n",
    "    for genre in genres_in_cluster:\n",
    "        if genre in actor_genre_ratings[actor]:  # Check if the actor has a rating for this genre\n",
    "            max_weighted_avg_rating = max(max_weighted_avg_rating, actor_genre_ratings[actor][genre])\n",
    "    \n",
    "    # Append the actor and their max weighted average rating to the cluster\n",
    "    actor_clusters_by_id[cluster].append((actor, max_weighted_avg_rating))\n",
    "\n",
    "# Sort actors within each cluster by max weighted average rating (descending)\n",
    "for cluster_id in actor_clusters_by_id:\n",
    "    actor_clusters_by_id[cluster_id].sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print\n",
    "for i in range(n_clusters):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "    print(f\"  Top 10 Actors: {[actor for actor, _ in actor_clusters_by_id[i][:10]]}\")  # Show only top 5 actors in each cluster\n",
    "    print(f\"  Genres: {genre_clusters_by_id[i]}\") "
   ],
   "id": "94694e7fb7615dbe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.cluster import SpectralBiclustering\n",
    "\n",
    "# Choose number of clusters\n",
    "n_clusters = 9\n",
    "model = SpectralBiclustering(n_clusters=n_clusters,  random_state=0)\n",
    "model.fit(adj_matrix)  # Convert sparse matrix to dense\n",
    "\n",
    "# actor → row labels\n",
    "# genre → column labels\n",
    "actor_clusters_biclust = model.row_labels_\n",
    "genre_clusters_biclust = model.column_labels_\n",
    "\n",
    "# Map back to names\n",
    "actor_cluster_mapping_biclust = {actor: cluster for actor, cluster in zip(actor_nodes, actor_clusters_biclust)}\n",
    "genre_cluster_mapping_biclust = {genre: cluster for genre, cluster in zip(genre_nodes, genre_clusters_biclust)}\n",
    "\n",
    "# Group actors and genres by cluster\n",
    "actor_clusters_by_id = defaultdict(list)\n",
    "genre_clusters_by_id = defaultdict(list)\n",
    "\n",
    "for genre, cluster in genre_cluster_mapping_biclust.items():\n",
    "    genre_clusters_by_id[cluster].append(genre)\n",
    "\n",
    "# Group actors by cluster and calculate the max weighted average rating for genres in the cluster\n",
    "for actor, cluster in actor_cluster_mapping_biclust.items():\n",
    "    # Get the genres in the same cluster\n",
    "    genres_in_cluster = genre_clusters_by_id[cluster]\n",
    "    \n",
    "    # Calculate the max weighted average rating for the actor across genres in the cluster\n",
    "    max_weighted_avg_rating = 0\n",
    "    for genre in genres_in_cluster:\n",
    "        if genre in actor_genre_ratings[actor]:  # Check if the actor has a rating for this genre\n",
    "            max_weighted_avg_rating = max(max_weighted_avg_rating, actor_genre_ratings[actor][genre])\n",
    "    \n",
    "    # Append the actor and their max weighted average rating to the cluster\n",
    "    actor_clusters_by_id[cluster].append((actor, max_weighted_avg_rating))\n",
    "\n",
    "# Sort actors within each cluster by max weighted average rating (descending)\n",
    "for cluster_id in actor_clusters_by_id:\n",
    "    actor_clusters_by_id[cluster_id].sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print\n",
    "for i in range(n_clusters):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "    print(f\"  Top 10 Actors: {[actor for actor, _ in actor_clusters_by_id[i][:10]]}\")  # Show only top 5 actors in each cluster\n",
    "    print(f\"  Genres: {genre_clusters_by_id[i]}\") "
   ],
   "id": "1d8240e0ba21d84b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(B.get_edge_data('Jon Bernthal', 'Drama'))\n",
    "print(B.get_edge_data('Lily James', 'Drama'))"
   ],
   "id": "af44fb44e9cd34ee"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
